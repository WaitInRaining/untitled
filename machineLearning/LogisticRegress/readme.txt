Logistic回归的一般过程
1、准备数据：由于需要进行距离计算，因此要求数据类型为数值型。另外，结构化数据格式最佳
2、分析数据：采用任意方法对数据进行分析
3、训练算法：大部分时间将用于训练，训练的目的是为了找到最佳的分类回归系数
4、测试算法：一旦训练步骤完成，分类将会很快
5、使用算法：首先，我们需要一些数据，并将其转换成对应的结构化数值；
    接着，基于训练好的回归系数就可以对这些数值进行简单的回归计算，判定它们属于哪个类别；
    在这之后，我们就可以在输出的类别上做一些其他分析工作。

Logistic回归;
优点：计算代价不高，易于理解和实现
缺点：容易欠拟合，分类精度可能不高
适用数据类型：数值型和标称型数据。

为实现Logistic回归分类器，我们可以在每个特征上都乘以一个回归系数（权重），然后把所有结果相加，将这个总和带入Sigmoid函数中，
进而得到一个范围在0-1之间的数值，大于0.5的被分为1类，小于0,5的被分为0类。
Sigmoid函数的输入为z,将z写成w的转置点乘x。而回归优化就是找到最好的w

第一个优化方法是梯度上升法：
    要找到某函数的最大值，最好的方法是沿着该函数的梯度方向探寻。梯度算子总是指向函数值增长最快的方向，每次移动后重新计算移动方向，
    直到满足某一条件位置。
    还有梯度下降法，与梯度上升不同的是，在公式计算时一个是加，一个是减
梯度下降法用来求函数的最小值，梯度上升法用来求函数的最大值



梯度上升的伪代码如下：
每个回归系数初始化为1
重复R次：
    计算整个数据集的梯度
    使用alpha 乘 gradient 更新回归系数的向量
    返回回归系数

 梯度上升法在每次更新回归系数的时候都需要遍历整个数据集，在计算量上非常大。
 对其进行改进，改进方法是一次仅用一个样本点来更新回归系数，该方法称为随机梯度上升。
 由于可以为新样本到来时对分类器进行增量式更新，因此随机梯度上升是一个在线学习算法。
 与“在线学习”相对应的，一次处理所有格式数据被称为“批处理”。
 随机梯度上升伪代码：
   所有回归系数初始划为1
   对数据集中每个样本：
            计算该样本的梯度
            使用alpha*gradient更新回归系数值
   返回回归系数值

   在使用Logistic回归估计马疝病的死亡率时，有一些数据特征缺失，需要先对数据进行处理，有如下几种方法可用：
  1、使用可用特征的均值来填补缺失值
  2、使用特殊值来填补缺失值，如-1或者null
  3、忽略有缺失值的样本
  4、使用相似样本的均值来添补缺失值
  5、使用另外的机器学习算法来预测缺失值

 在此处做一下处理：
 1、所有缺失值使用一个实数值进行替换，选择0来替换所有缺失值，因为sigmoid(0) = 0.5，不对结果的预测有任何倾向性
 2、如果在测试数据集中发现了一条数据的类别标签已经缺失，那么我们的简单做法是将该条数据丢弃







